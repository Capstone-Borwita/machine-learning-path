{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ug_r7TQ9GS0X"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9-fndyDGTxW",
    "outputId": "e095a799-7d16-4ce5-ea65-4c6de8842120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 558 images belonging to 2 classes.\n",
      "Found 138 images belonging to 2 classes.\n",
      "Class Indices (Train): {'KTP': 0, 'non_KTP': 1}\n",
      "Class Indices (Validation): {'KTP': 0, 'non_KTP': 1}\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    zoom_range=0.2, \n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "# Load training and validation datasets\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"/content/drive/MyDrive/dataset/train\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    \"/content/drive/MyDrive/dataset/val\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# indices\n",
    "print(\"Class Indices (Train):\", train_data.class_indices)\n",
    "print(\"Class Indices (Validation):\", val_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khbaCqqfGaCP",
    "outputId": "865ac8bb-5eef-46f4-df9a-567e1d0632d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.trainable = False  # Freeze base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gg_ybO-AGfiZ"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),  # 30% dropout\n",
    "    layers.Dense(1, activation=\"sigmoid\") #binary\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model with additional metrics and learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nOEAStzgGi07"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True  # Unfreeze the base model\n",
    "\n",
    "# Fine-tune from a specific layer\n",
    "for layer in base_model.layers[:100]:  # Freeze initial 100 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OTKeyKibGkv_"
   },
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DJoXiB7GnBL",
    "outputId": "01dc6ba3-bfd3-4fb8-8579-9198cdec1505"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 98s 5s/step - loss: 0.3913 - accuracy: 0.8405 - precision: 0.8393 - recall: 0.8423 - val_loss: 0.3140 - val_accuracy: 0.8841 - val_precision: 0.8732 - val_recall: 0.8986\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 14s 796ms/step - loss: 0.1235 - accuracy: 0.9606 - precision: 0.9509 - recall: 0.9713 - val_loss: 0.1980 - val_accuracy: 0.9348 - val_precision: 0.9688 - val_recall: 0.8986\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 14s 796ms/step - loss: 0.0765 - accuracy: 0.9785 - precision: 0.9751 - recall: 0.9821 - val_loss: 0.1468 - val_accuracy: 0.9348 - val_precision: 0.9054 - val_recall: 0.9710\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 14s 779ms/step - loss: 0.0368 - accuracy: 0.9910 - precision: 0.9964 - recall: 0.9857 - val_loss: 0.1406 - val_accuracy: 0.9493 - val_precision: 0.9079 - val_recall: 1.0000\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 14s 796ms/step - loss: 0.0601 - accuracy: 0.9892 - precision: 0.9928 - recall: 0.9857 - val_loss: 0.1517 - val_accuracy: 0.9275 - val_precision: 0.8734 - val_recall: 1.0000\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 14s 807ms/step - loss: 0.0250 - accuracy: 0.9928 - precision: 0.9964 - recall: 0.9892 - val_loss: 0.1249 - val_accuracy: 0.9493 - val_precision: 0.9079 - val_recall: 1.0000\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 14s 787ms/step - loss: 0.0143 - accuracy: 0.9982 - precision: 1.0000 - recall: 0.9964 - val_loss: 0.0916 - val_accuracy: 0.9565 - val_precision: 0.9315 - val_recall: 0.9855\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 14s 793ms/step - loss: 0.0127 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9493 - val_precision: 0.9189 - val_recall: 0.9855\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 14s 798ms/step - loss: 0.0226 - accuracy: 0.9946 - precision: 0.9964 - recall: 0.9928 - val_loss: 0.0469 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 14s 795ms/step - loss: 0.0210 - accuracy: 0.9892 - precision: 0.9858 - recall: 0.9928 - val_loss: 0.0532 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 14s 774ms/step - loss: 0.0117 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - val_loss: 0.0353 - val_accuracy: 0.9855 - val_precision: 1.0000 - val_recall: 0.9710\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 14s 784ms/step - loss: 0.0171 - accuracy: 0.9946 - precision: 0.9929 - recall: 0.9964 - val_loss: 0.0436 - val_accuracy: 0.9855 - val_precision: 0.9718 - val_recall: 1.0000\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 14s 782ms/step - loss: 0.0167 - accuracy: 0.9946 - precision: 1.0000 - recall: 0.9892 - val_loss: 0.0530 - val_accuracy: 0.9783 - val_precision: 0.9714 - val_recall: 0.9855\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 14s 776ms/step - loss: 0.0079 - accuracy: 0.9982 - precision: 0.9964 - recall: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9710 - val_precision: 0.9452 - val_recall: 1.0000\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 14s 783ms/step - loss: 0.0091 - accuracy: 0.9964 - precision: 0.9929 - recall: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 14s 825ms/step - loss: 0.0053 - accuracy: 0.9982 - precision: 1.0000 - recall: 0.9964 - val_loss: 0.0551 - val_accuracy: 0.9783 - val_precision: 0.9714 - val_recall: 0.9855\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 14s 792ms/step - loss: 0.0029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9783 - val_precision: 0.9714 - val_recall: 0.9855\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 14s 786ms/step - loss: 0.0024 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 14s 790ms/step - loss: 0.0027 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0384 - val_accuracy: 0.9855 - val_precision: 0.9855 - val_recall: 0.9855\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 14s 797ms/step - loss: 0.0050 - accuracy: 0.9982 - precision: 1.0000 - recall: 0.9964 - val_loss: 0.0289 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 14s 780ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 14s 786ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 14s 781ms/step - loss: 0.0015 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 14s 798ms/step - loss: 0.0013 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 14s 778ms/step - loss: 0.0035 - accuracy: 0.9982 - precision: 1.0000 - recall: 0.9964 - val_loss: 0.0257 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 14s 785ms/step - loss: 0.0050 - accuracy: 0.9982 - precision: 0.9964 - recall: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9928 - val_precision: 0.9857 - val_recall: 1.0000\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 14s 776ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9928 - val_precision: 0.9857 - val_recall: 1.0000\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 14s 776ms/step - loss: 0.0020 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9928 - val_precision: 0.9857 - val_recall: 1.0000\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 14s 789ms/step - loss: 0.0022 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9783 - val_precision: 0.9583 - val_recall: 1.0000\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 14s 776ms/step - loss: 0.0035 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 14s 777ms/step - loss: 0.0010 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9928 - val_precision: 1.0000 - val_recall: 0.9855\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yRjxlm-Go6y",
    "outputId": "2e3f5ce5-060c-4643-94ff-9e3eb7ea49b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 450ms/step - loss: 0.0179 - accuracy: 0.9928 - precision: 1.0000 - recall: 0.9855\n",
      "Validation Loss: 0.0179\n",
      "Validation Accuracy: 0.9928\n",
      "Validation Precision: 1.0000\n",
      "Validation Recall: 0.9855\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "loss, accuracy, precision, recall = model.evaluate(val_data)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKywRNxmGsm5",
    "outputId": "5aeab2b7-4aa5-4bca-ab3d-905dc219568a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 465ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.46      0.46        69\n",
      "           1       0.46      0.46      0.46        69\n",
      "\n",
      "    accuracy                           0.46       138\n",
      "   macro avg       0.46      0.46      0.46       138\n",
      "weighted avg       0.46      0.46      0.46       138\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32 37]\n",
      " [37 32]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the validation dataset\n",
    "val_preds = (model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "true_labels = val_data.classes\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, val_preds))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Obo0EOsmJgyn",
    "outputId": "94762da3-e5a9-4a4b-e3a4-fec1df8253c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mobilenetv2_1.00_224_input']\n",
      "['mobilenetv2_1.00_224_input']\n"
     ]
    }
   ],
   "source": [
    "print(model.input_names)\n",
    "model.get_layer(index=0)._name = \"mobilenetv2_input\"\n",
    "print(model.input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jLI6ONwGwlk",
    "outputId": "72facf1e-c5b2-40c3-f88f-eb86aaa36b36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model saved at /content/ktp_classifier.tflite\n"
     ]
    }
   ],
   "source": [
    "# Save the model as TFLite\n",
    "tflite_model_path = \"/content/ktp_classifier2.tflite\"\n",
    "\n",
    "# Convert the model to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model saved at {tflite_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tflite_model_path = \"ktp_classifier2.tflite\"\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Define image size and class labels\n",
    "IMG_SIZE = (224, 224)\n",
    "class_labels = {0: \"KTP\", 1: \"Not KTP\"}\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image to match the model input requirements.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, IMG_SIZE)\n",
    "    img_normalized = img_resized / 255.0\n",
    "    return np.expand_dims(img_normalized, axis=0).astype(np.float32)\n",
    "\n",
    "def testWithFolder(test_folder,expectedLabel):\n",
    "    for file_name in os.listdir(test_folder):\n",
    "        file_path = os.path.join(test_folder, file_name)\n",
    "        if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        input_data = preprocess_image(file_path)\n",
    "\n",
    "        # inference\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        # Get prediction and confidence score\n",
    "        confidence = output_data[0][0]\n",
    "        predicted_label = class_labels[1] if confidence > 0.5 else class_labels[0]\n",
    "        correctLabel = f\"[{'✓' if predicted_label == expectedLabel else '✗'}]\"\n",
    "        # Print result\n",
    "        print(f\"Image: {file_name}\\n Prediction: {predicted_label} Should be {expectedLabel}\\n{correctLabel}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: download (1).jpg\n",
      " Prediction: Not KTP Should be KTP\n",
      "[✗]\n",
      "\n",
      "Image: download (2).jpg\n",
      " Prediction: Not KTP Should be KTP\n",
      "[✗]\n",
      "\n",
      "Image: download.jpg\n",
      " Prediction: KTP Should be KTP\n",
      "[✓]\n",
      "\n",
      "Image: images (1).jpg\n",
      " Prediction: Not KTP Should be KTP\n",
      "[✗]\n",
      "\n",
      "Image: images (2).jpg\n",
      " Prediction: KTP Should be KTP\n",
      "[✓]\n",
      "\n",
      "Image: images (3).jpg\n",
      " Prediction: KTP Should be KTP\n",
      "[✓]\n",
      "\n",
      "Image: images.jpg\n",
      " Prediction: KTP Should be KTP\n",
      "[✓]\n",
      "\n",
      "Image: download (1).jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: download (2).jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: download (3).jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: download (4).jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: download.jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: images (1).jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n",
      "Image: images.jpg\n",
      " Prediction: Not KTP Should be Not KTP\n",
      "[✓]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_KTP = r\"tesKTP\"\n",
    "test_NonKTP = r\"tesNonKTP\"\n",
    "\n",
    "testWithFolder(test_KTP, \"KTP\")\n",
    "testWithFolder(test_NonKTP, \"Not KTP\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
